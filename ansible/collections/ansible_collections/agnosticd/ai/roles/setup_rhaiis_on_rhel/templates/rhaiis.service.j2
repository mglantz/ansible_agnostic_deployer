[Unit]
Description=RHAIIS Service
After=network.target

[Service]
Type=simple
Environment="HUGGING_FACE_HUB_TOKEN={{ hf_token }}"
Environment="HF_HUB_OFFLINE=0"
User={{ vllm_user }}
ExecStart=/usr/bin/podman run --rm -it --device nvidia.com/gpu=all -p {{ vllm_port }}:8000 \
    --ipc=host \
    --env "HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}" \
    --env "HF_HUB_OFFLINE=${HF_HUB_OFFLINE}" \
    -v {{ vllm_cache_dir }}:/home/vllm/.cache \
    --name={{ vllm_container_name }} \
    {{ vllm_container_image }} \
    vllm serve \
    --tensor-parallel-size {{ vllm_tensor_parallel_size }} \
    --max-model-len {{ vllm_max_model_len }} \
    --enforce-eager {{ vllm_model }}
ExecStop=/usr/bin/podman stop {{ vllm_container_name }}
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
