[Unit]
Description=RHAIIS Service
After=network.target

[Service]
Type=simple
Environment="HUGGING_FACE_HUB_TOKEN={{ setup_rhaiis_on_rhel_hf_token }}"
Environment="HF_HUB_OFFLINE=0"
User={{ student_name | default('dev') }}
ExecStart=/usr/bin/podman run --rm -it --device nvidia.com/gpu=all -p {{ setup_rhaiis_on_rhel_vllm_port }}:8000 \
    --ipc=host \
    --env "HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}" \
    --env "HF_HUB_OFFLINE=${HF_HUB_OFFLINE}" \
    -v {{ setup_rhaiis_on_rhel_vllm_cache_dir }}:/home/vllm/.cache \
    --name={{ setup_rhaiis_on_rhel_vllm_container_name }} \
    {{ setup_rhaiis_on_rhel_vllm_container_image }} \
    vllm serve \
    --tensor-parallel-size {{ setup_rhaiis_on_rhel_vllm_tensor_parallel_size }} \
    --max-model-len {{ setup_rhaiis_on_rhel_vllm_max_model_len }} \
    --enforce-eager {{ setup_rhaiis_on_rhel_vllm_model }}
ExecStop=/usr/bin/podman stop {{ setup_rhaiis_on_rhel_vllm_container_name }}
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
